# base_agent.py (or could be part of your main script for now)
import os
from dotenv import load_dotenv

from abc import ABC, abstractmethod
from openai import OpenAI
from openai import OpenAIError # Specific error class for OpenAI API issues

class BaseAgent(ABC):
    """
    Abstract Base Class for all agents in the PrecisionAI system.
    Handles common functionalities like OpenAI API interaction.
    """
    def __init__(self, model: str = "gpt-4o", temperature: float = 0.7, max_tokens: int = 2000):
        """
        Initializes the BaseAgent with OpenAI API client and default parameters.
        Args:
            model (str): The OpenAI model to use (e.g., "gpt-4o", "gpt-4-turbo").
            temperature (float): Controls creativity. Higher values (up to 1.0) mean more random output.
            max_tokens (int): The maximum number of tokens to generate in the completion.
        """
        load_dotenv()
        # Ensure API key is set via environment variable for security
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set.")
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

    def _call_llm(self, system_message: str, user_message: str = None) -> str:
        """
        Internal method to make a call to the OpenAI Chat Completions API.
        Args:
            system_message (str): The system role message to guide the LLM.
            user_message (str, optional): The user role message. Defaults to None.
        Returns:
            str: The content generated by the LLM.
        Raises:
            OpenAIError: If there's an issue with the OpenAI API call.
            Exception: For other unexpected errors.
        """
        messages = [{"role": "system", "content": system_message}]
        if user_message:
            messages.append({"role": "user", "content": user_message})

        try:
            chat_completion = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )
            return chat_completion.choices[0].message.content
        except OpenAIError as e:
            print(f"OpenAI API Error in {self.__class__.__name__}: {e}")
            raise # Re-raise the exception to be handled upstream
        except Exception as e:
            print(f"An unexpected error occurred in {self.__class__.__name__}: {e}")
            raise # Re-raise the exception


    @abstractmethod
    def generate(self, *args, **kwargs) -> str:
        """
        Abstract method that must be implemented by concrete agent classes.
        This method will contain the specific logic for each agent's task.
        """
        pass